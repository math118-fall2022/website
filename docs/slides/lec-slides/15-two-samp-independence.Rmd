---
title: "Two-sample inference"
subtitle: "Difference in proportions"
author: "Becky Tang"
date: "11/4/2022"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "math118-slides.css"
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
---



layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 3, fig.width = 5, dpi = 300, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = "center") 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(openintro)
library(infer)
library(patchwork)
library(kableExtra)
```

---


## Recap

We saw how to compare two sample *means* against each other.

.question[
What if we wanted to compare two sample *proportions* against each othery?
]

---


class: center, middle

# Permutation tests for proportions

---

## Is yawning contagious?

.pull-left[
![](img/15/yawn1.png)
]
.pull-right[
![](img/15/yawn2.png)
]

---

## Is yawning contagious?

An experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.

They recruited 50 people, spoke to each subject one-one-one, and intentially either yawned
or did not yawn during the session. Each subject sat in a small room for a fixed amount of time, and the Mythbusters secretly observed to see whether they yawned.

---

## Description

Randomly assigned people to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn't see someone yawn (control).

```{r echo = F}
group <- c(rep("control", 16), rep("treatment", 34))
outcome <- c(rep("no yawn", 12), rep("yawn", 4), rep("no yawn", 24), rep("yawn", 10))
mb_yawn <- data.frame(group = group, outcome = outcome) %>%
  sample_n(size = 50)
```

```{r}
glimpse(mb_yawn)
mb_yawn %>%
  count(group, outcome)
```

---

## Proportion of yawners

```{r}
mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(rel_prop = round(n / sum(n), 2))
```

The Mythbusters claimed that the difference in proportion of yawners between the two groups (0.04) was significant, based on intuition. Let's see if hypothesis testing agrees...

---

## Independence? 

Based on the proportions we calculated, do you think yawning is really contagious, i.e. are seeing someone yawn and yawning dependent?

```{r echo = F}
mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(p_hat = round(n / sum(n), 2))
```

---

## Possible explanations

- The observed differences might suggest that yawning is contagious, i.e. seeing someone yawn and yawning are dependent

- But the differences are small enough that we might wonder if they might simple be **due to chance**

- If we were to repeat the experiment on another group of 50 people, we may see different results. So let's simulate using a **permutation test**

---

## Hypotheses

$H_0$: yawning (outcome) and seeimg someone yawn (treatment vs. control) are independent:

$$p_{treat} = p_{control}$$

$H_{a}$: yawning and seeing someone yawn are not independent (in fact, we will specify that the proportion of yawners is greater in the treatment group than in the control group:

$$p_{treat} > p_{control}$$

where $p_{treat}$ is the true proportion of yawners among those who saw someone else yawn, and similarly for 
$p_{control}$.

Note, these are equivalent to $H_0: p_{treat} - p_{control} = 0$ and $H_a: p_{treat} - p_{control} > 0$.

---

## Permuting the treatment assignments

We know from our observed data that 14 people yawned and 36 people didn't yawn.

We also know that there were 16 people in the control group (didn't see someone yawn) and 34 people in the treatment group (saw someone yawn), resulting in an *observed* test statistic of 0.0441.

```{r}
p_hat_diff <- mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(p_hat = n / sum(n)) %>%
  filter(outcome == "yawn") %>%
  pull(p_hat) %>%
  diff() #<<
p_hat_diff
```

.question[What does `diff()` do?]

---

```{r}
mb_yawn %>%
  count(group, outcome) %>%
  group_by(group) %>%
  mutate(p_hat = n / sum(n), 2) %>%
  filter(outcome == "yawn") 

p_hat_diff
```

---

##  Permuting the treatment assignments

While keeping the responses (yawn vs. no yawn) fixed at what we observed, we will *permute* or shuffle the treatment assignments of the observations and recalculate the difference in proportions.

That is, we will recalculate the difference in proportions as if some of the yawners and some of the non-yawners perhaps might have been in a different treatment group.

--

Why do we do this?

---

## The null hypothesis

Recall that under $H_0$, there is no association between seeing someone yawn (treatment vs control) and the act of yawning (outcome).

If there truly is no association between treatment and control, then shuffling whether someone was assigned to watch somebody yawn or not yawn shouldn't matter -- we would expect similar proportions of people who yawn in each group.

--

Because we are in the hypothesis testing framework, we generate our null distribution assuming $H_0$ true. How can we obtain that null distribution?

---

## Repeated permutations

We will do this treatment-shuffling again and again, calculate the difference in proportion for each simulation, and use this as an approximation to the null distribution.

This distribution approximates all the possible differences in proportion we could have seen if 
$H_0$ were in fact true. 

This is similar in spirit to bootstrap estimation, but here we **sample without replacement**; we merely permute/shuffle the treatment labels of each of our outcomes.


---

## Using `infer`

```{r eval = F}
null_dist <- mb_yawn %>%
  specify(response = outcome, explanatory = group, success = "yawn") %>%  #<<
  hypothesize(null = "independence") %>%
  generate(1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("treatment", "control"))
```

Because we are interested in the whether or not someone yawned, `response = outcome`.

We are comparing the proportions between two levels of the variable `group`, so `explanatory = group`.

Since the response variable is categorical, specify which level should be success

---

## Using `infer`

```{r eval = F}
null_dist <- mb_yawn %>%
  specify(response = outcome, explanatory = group, success = "yawn") %>%  
  hypothesize(null = "independence") %>% #<<
  generate(1000, type = "permute") %>% 
  calculate(stat = "diff in props", order = c("treatment", "control"))
```

Null hypothesis: the outcome and treatment are independent.

---


## Using `infer`

```{r eval = F}
null_dist <- mb_yawn %>%
  specify(response = outcome, explanatory = group, success = "yawn") %>%  
  hypothesize(null = "independence") %>% 
  generate(1000, type = "permute") %>% #<<
  calculate(stat = "diff in props", order = c("treatment", "control"))
```

Generate simulated results via permutation

---

## Using `infer`

```{r}
set.seed(100)
null_dist <- mb_yawn %>%
  specify(response = outcome, explanatory = group, success = "yawn") %>%  
  hypothesize(null = "independence") %>% 
  generate(1000, type = "permute") %>% 
  calculate(stat = "diff in props", order = c("treatment", "control"))#<<
```

Calculate the sample statistic of interest (difference in proportions). 

Because the explanatory variable `group` is categorical, we need to tell R the
order in which to take the different in proportions for the calculation: $(\hat{p}_{treat} - \hat{p}_{control})$.

---

## Visualizing the null distribution

What would you expect the center of the null distribution to be?


```{r fig.height=2}
visualize(null_dist) 
```

---

## Calculating the p-value

```{r}
null_dist %>%
  filter(stat >= p_hat_diff) %>%
  summarise(p_val = n()/nrow(null_dist))
```


.question[What is the conclusion of our hypothesis test?]

