---
title: "Multiple linear regression"
author: "Becky Tang"
date: "11/30/2022"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "math118-slides.css"
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
editor_options: 
  chunk_output_type: console
---


<!-- layout: true -->

<!-- <div class="my-footer"> -->
<!-- <span> -->
<!-- <a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a> -->
<!-- </span> -->
<!-- </div>  -->


```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 3, fig.width = 5, dpi = 300, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = "center") 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(patchwork)
```

---

class: center, middle

## Review

---


## Vocabulary


- .vocab[Response variable]: Variable whose behavior or variation you are trying 
to understand. 


- .vocab[Explanatory variables]: Other variables that you want to use to explain
the variation in the response.



- .vocab[Residuals]: Shows how far each case is from its predicted value
   - **Residual = Observed value - Predicted value**

---

## The linear model with a single predictor

- We're interested in the $\beta_0$ (population parameter for the intercept)
and the $\beta_1$ (population parameter for the slope) in the 
following model:

$$ \hat{y} = \beta_0 + \beta_1~x $$

--

- Unfortunately, we can't get these values

- So we use sample statistics to estimate them:

$$ \hat{y} = b_0 + b_1~x $$


---

## Data and Packages

```{r eval = FALSE}
library(tidyverse)
library(broom)
```

```{r message=FALSE, echo = F}
sports_car_prices <- read_csv("data/sports_cars.csv") %>%
  rename("type" = "car")
glimpse(sports_car_prices)
```

The data set contains prices for Porsche and Jaguar cars for sale
on cars.com.

.vocab[`type`]: car make (Jaguar or Porsche)

.vocab[`price`]: price in USD

.vocab[`age`]: age of the car in years

.vocab[`mileage`]: previous miles driven


---

## Single numerical predictor 

```{r}
mod_pr_age <- lm(price ~ age, data = sports_car_prices)
tidy(mod_pr_age)
```

$$\widehat{price} = 53246- 2149 ~age_{years}$$

---

## Single categorical predictor (2 levels)

```{r}
mod_pr_type <- lm(price ~ type, data = sports_car_prices)
tidy(mod_pr_type)
```

$$\widehat{price} = 31956.67	 +18580 ~typePorsche$$

---

## Single categorical predictor (2 levels)

$$\widehat{price} = 31956.67	 + 18580 ~typePorsche$$

What is the the average price of a Porsche?

--

For Porsches, $typePorsche = 1$. So the average price of Porsches is 
$$\widehat{price} = 31956.67	 + 18580 \times 1 =  50536.67$$


---


class: center, middle

## The linear model with multiple predictors


---

## The linear model with multiple predictors

- Population model:

$$\hat{y} = \beta_0 + \beta_1~x_1 + \beta_2~x_2 + \cdots + \beta_p~x_p$$

where $p$ is the number of explanatory variables.

--

- Sample model that we use to estimate the population model:
  
$$\hat{y} = b_0 + b_1~x_1 + b_2~x_2 + \cdots + b_p~x_p$$


---

## Price and age

```{r echo=FALSE, warning=FALSE, fig.height = 2}
ggplot(data = sports_car_prices, 
       aes(x = age, y = price)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = F) + 
  labs(x = "Age (years)", y = "Price (USD)", color = "Car Make")+
  ggtitle("Price vs age of sports cars")
```


---


## Price vs. age and make

.question[
Can we model simultaneously model the relationships between the age and make of a used car and its price?
]

```{r echo = FALSE, fig.height = 2}
ggplot(data = sports_car_prices, 
       aes(x = age, y = price, color = type)) + 
  geom_point() +
  # geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Age (years)", y = "Price (USD)", color = "Car Make")
```

---

### Modeling with multiple predictors

.question[What is the linear regression model for `price` that uses both `age` and `type` of the car as predictors?]

$$\widehat{price} = \beta_{0} + \beta_{1}~ age + \beta_{2}~type$$
--

- Our estimated linear regression model:

```{r}
m_main <- lm(price ~ age + type, data = sports_car_prices)
m_main %>%
  tidy() %>%
  select(term, estimate)
```

--

.midi[
$$ \widehat{price} = 44310 - 2487~age + 21648~typePorsche $$
]

---

### Different lines for each level

.alert[
$$ \widehat{price} = 44310 - 2487~age + 21648~typePorsche $$
]


- What is the linear model for Porsches? Plug in 1 for `typePorsche`:

$$\begin{align}\widehat{price}_{porsche} &= 44310 - 2487~age + 21648 \times 1 \\
&= 65958 - 2487~age\\\end{align}$$

--

- What is the linear model for Jaguars? Plug in 0 for `typePorsche`:


$$\begin{align}\widehat{price}_{jaguar} &= 44310 - 2487~age + 21648 \times 0\\
&= 44310 - 2487~age\\\end{align}$$

---

### Different lines for each level (cont.)

.alert[
**Jaguar**

$$\begin{align}\widehat{price}_{jaguar} = 44310 - 2487~age\\\end{align}$$

**Porsche**

$$\begin{align}\widehat{price}_{porsche} = 65958 - 2487~age\\\end{align}$$
]

- Rate of change in price as the age of the car increases does not depend on 
make of car (.vocab[same coefficient for age!])

- Porsches are consistently more expensive than Jaguars (.vocab[different intercepts])

---

### Different lines for each level (cont.)

```{r echo = FALSE, fig.height = 2}
int_jag <- m_main %>%
  tidy() %>%
  slice(1) %>%
  pull(estimate)
int_porsche <- m_main %>%
  tidy() %>%
  slice(c(1,3)) %>%
  pull(estimate) %>%
  sum()
slope <- m_main %>%
  tidy() %>%
  slice(2) %>%
  pull(estimate)
ggplot(data = sports_car_prices, 
       aes(x = age, y = price, color = type)) + 
  geom_point() +
  geom_abline(slope = slope, intercept = int_jag, col = "#F8766D", lwd = 1)+
  geom_abline(slope = slope, intercept = int_porsche, col = "#00BFC4", lwd = 1)+
  labs(x = "Age (years)", y = "Price (USD)", color = "Car Make")+
  ggtitle("Fitted regression lines by car make")
```

---

## Interpretation

```{r echo=FALSE}
m_main %>%
  tidy() %>%
  select(term, estimate)
```

```{r include=FALSE}
m_main_coefs <- m_main %>%
  tidy() %>%
  select(term, estimate)
```

.alert[
$$ \widehat{price} = 44310 - 2487~age + 21648~typePorsche $$
]

--

- **All else held constant**, for each additional year of a car's age, the price of the car is predicted to *decrease*, on average, by $2,487.

--

- **All else held constant**, Porsches are predicted, on average, to have a 
price that is $21,648 greater than Jaguars.

--

- Jaguars that are new (`age` = 0) are predicted, on average, to have a price of $44,309.


---

class: center, middle

## Assessing quality of model fit

---

## Assessing the quality of the fit

- The strength of the fit of a linear model is commonly evaluated using $R^2$, sometimes called the .vocab[coefficient of determination]

- It tells us what percentage of the variability in the response variable is explained by the model. The remainder of the variability is unexplained.

  - The $R^2$ is always between 0 and 100 (or 0 and 1)
  
--


.question[
What does "explained variability in the response variable" mean?
]

--

.question[What does an $R^2 = 1$ tell us? What about an $R^2 = 0$?]

---

## Obtaining $R^2$ in R

The $R^2$ of our model is:

```{r}
glance(m_main)
glance(m_main) %>%
  pull(r.squared)
```

--

- Interpretation: about 60.7% of the variability in `price` of used cars can be explained by `age` and `type`


