---
title: "Functions and automation"
author: "Dr. Maria Tackett"
date: "09.26.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta199-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs
    nature: 
      highlightLines: true
      highlightStyle: github
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 

---

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(emo)
library(openintro)
library(infer)
library(gridExtra)
```

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

class: middle, center

### [Click for PDF of slides](06b-functions.pdf)

---

### Announcements

- Writing Exercise #2 initial draft - **due TODAY at 11:59p**
    - Peer Review available tomorrow and due Sunday 9/29 at 11:59p

- HW 02 - **due TODAY at 11:59p**

- Team Feedback #1 **due TODAY at 11:59p**
    - Please provide honest and constructive feedback. This team feedback will be graded for completion.
    

---

### Check in: Regrade Requests

- All regrade requests should be submitted through Gradescope. [See updated course policy](https://www2.stat.duke.edu/courses/Fall19/sta199.001/policies.html)

- Only submit a regrade request if you still have concerns about your grade after you have attended office hours and asked a member of the teaching team to explain the feedback you received. This will ultimately help with your understanding of the course material and help the teaching team get an idea about points to clarify.

- **When you submit a regrade request, please indicate who you've talked with prior to submitting the request.**

- Professor Tackett is the only person who can update grades, so <u>do not</u> ask your TAs to regrade your assignment.
   
---

### Check in: Lab 04

- Will get Lab 04 assignment from RStudio Cloud project. 

- [Fill out form](https://forms.gle/Ci8XCcHh6ESvuac6A) with the name of the RStudio Cloud project for grading.

---

class: middle, center

# Web scraping 

```{r echo = F, message=FALSE}
library(rvest)

page <- read_html("http://www.imdb.com/chart/top")

titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()

years <- page %>%
  html_nodes(".secondaryInfo") %>%
  html_text() %>%
  str_replace("\\(", "") %>% # remove (
  str_replace("\\)", "") %>% # remove )
  as.numeric()

scores <- page %>%
  html_nodes(".imdbRating") %>%
  html_text() %>%
  as.numeric()
  
imdb_top_250 <- tibble(
  title = titles, 
  year = years, 
  score = scores
  )
```

---

### Clean up / enhance

May or may not be a lot of work depending on how messy the data are

- See if you like what you got:

```{r}
glimpse(imdb_top_250)
```

- Add a variable for rank
```{r}
imdb_top_250 <- imdb_top_250 %>%
  mutate(
    rank = 1:nrow(imdb_top_250)
  )
```

---

```{r echo=FALSE, results='asis'}
imdb_top_250 %>% head(10)%>% rbind(rep("...", 3)) %>% kable(format = "html")
```

---

### Analyze

.question[
How would you go about answering this question: Which 1995 movies made the list?
]

---

```{r}
imdb_top_250 %>% 
  filter(year == 1995)
```

---

### Analyze

.question[
How would you go about answering this question: Which years have the most movies on the list?
]

--

```{r}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(total = n()) %>%
  arrange(desc(total)) %>%
  head(5)
```

---

### Visualize

.question[
How would you go about creating this visualization: Visualize the average yearly score for movies that made it on the top 250 list over time.
]

--

.small[
```{r echo=FALSE}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(avg_score = mean(score)) %>%
  ggplot(aes(y = avg_score, x = year)) +
    geom_point() +
    geom_smooth(method = "lm") +
    xlab("year")
```
]

---

### Top Rated 

.question[
- Which year has the highest average score for movies that made the Top 250? 
]

--

.question[
- What is one reason we should write code to answer this question rather than look through the data?
- What is one reason we only want to print the year with the highest average rather than entire table?
]

---

### Potential challenges

- Unreliable formatting at the source
- Data broken into many pages
- ...

.question[
Compare the display of information at [raleigh.craigslist.org/search/apa](https://raleigh.craigslist.org/search/apa) to the list on the IMDB top 250 list. 

What challenges can you foresee in scraping a list of the available apartments?
]

---

class: middle, center

## Application Exercise

---

### Popular TV Shows

RStudio Cloud $\rightarrow$ Web scraping 

1. Scrape the list of most popular TV shows on IMDB: http://www.imdb.com/chart/tvmeter

2. Examine each of the first three (or however many you can get through) tv show subpage to also obtain genre and runtime.

3. Time permitting, also try to get the following:

    - How many episodes so far
    - Certificate
    - First five plot keywords
    - Country
    - Language

Add this information to the data frame you created in step 1.

---
class: middle, center
### Writing More Efficient Code 

---

### Writing Exercise #1: Original code

```{r eval = F}
# create data set for each education level
educ_1 <- NHANES %>% 
  filter(Education=="8th Grade") %>%
  select(HomeOwn)

educ_2 <- NHANES %>% 
  filter(Education=="9 - 11th Grade") %>%
  select(HomeOwn)

educ_3 <- NHANES %>% 
  filter(Education=="High School") %>%
  select(HomeOwn)

educ_4 <- NHANES %>% 
  filter(Education=="Some College") %>%
  select(HomeOwn)

educ_5 <- NHANES %>% 
  filter(Education=="College Grad") %>%
  select(HomeOwn)
```

---

### Writing Exercise #1: Original Code

```{r eval = F}
# calculate proportion of HomeOwn
educ_1 %>%
  count(HomeOwn) %>%
  mutate(proportion = n/sum(n))

educ_2 %>%
  count(HomeOwn) %>%
  mutate(proportion = n/sum(n))

educ_3 %>%
  count(HomeOwn) %>%
  mutate(proportion = n/sum(n))

educ_4 %>%
  count(HomeOwn) %>%
  mutate(proportion = n/sum(n))

educ_5 %>%
  count(HomeOwn) %>%
  mutate(proportion = n/sum(n))
```


---

### Writing Exercise #1: Efficient code

```{r eval = F}
NHANES %>%
  group_by(Education) %>%
  count(HomeOwn) %>%
  mutate(proportion=n/sum(n))
```

.question[
- What are two reasons we prefer to write code in this efficient way instead of in the original format?
]

---

class: center, middle

# Functions

---

### Setup


```{r, warning = F, message = F}
library(tidyverse)
library(rvest)

pb <- read_html("https://www.imdb.com/title/tt2442560/")
st <- read_html("https://www.imdb.com/title/tt4574334/")
fr <- read_html("https://www.imdb.com/title/tt0108778/")
```


---

### Why functions?

- Automate common tasks in a power powerful and general way than copy-and-pasting:
    - You can give a function an evocative name that makes your code easier to understand.
    - As requirements change, you only need to update code in one place, instead of many.
    - You eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).

--

- Down the line: Improve your reach as a data scientist by writing functions (and packages!) that others use

---

### When should you write a function?

Whenever youâ€™ve copied and pasted a block of code more than twice.

.question[
Do you see any problems in the code below?
]

.small[
```{r eval=FALSE}
pb_episode <- st %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()

st_episode <- got %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()

fr_episode <- twd %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()
```
]

---

### Inputs

.question[
How many inputs does the following code have?
]

```{r eval=FALSE}
st_episode <- st %>%
  html_nodes(".np_right_arrow .bp_sub_heading") %>%
  html_text() %>%
  str_replace(" episodes", "") %>%
  as.numeric()
```

---

### Turn your code into a function

1. Pick a short but informative <font class="vocab">name</font>, preferably a verb.

<br>
<br>
<br>
<br>

```{r eval=FALSE}
scrape_episode <- 
  
  
  
  
  
  
```

---

### Turn your code into a function

1. Pick a short but informative **name**, preferably a verb.
2. List inputs, or <font class="vocab">arguments</font>, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.

<br>

```{r eval=FALSE}
scrape_episode <- function(x){
  
  
  
  
  
}  
```

---

### Turn your code into a function

1. Pick a short but informative **name**, preferably a verb.
2. List inputs, or **arguments**, to the function inside `function`. If we had more the call would look like `function(x, y, z)`.
3. Place the <font class="vocab">code</font> you have developed in body of the function, a `{` block that immediately follows `function(...)`.

```{r}
scrape_episode <- function(x){
  x %>%
    html_nodes(".np_right_arrow .bp_sub_heading") %>%
    html_text() %>%
    str_replace(" episodes", "") %>%
    as.numeric()
}
```

--

```{r}
scrape_episode(st)
```

---

### Check your function

[Peaky Blinders](https://www.imdb.com/title/tt2442560/)

```{r}
scrape_episode(pb)
```

[Friends](https://www.imdb.com/title/tt0108778/)

```{r}
scrape_episode(fr)
```

---

### Naming functions

> "There are only two hard things in Computer Science: cache invalidation and naming things." - Phil Karlton

--

- Names should be short but clearly evoke what the function does

--

- Names should be verbs, not nouns

--

- Multi-word names should be separated by underscores (`snake_case` as opposed to `camelCase`)

--

- A family of functions should be named similarly (`scrape_title`, `scrape_episode`, `scrape_genre`, etc.)

--

- Avoid overwriting existing (especially widely used) functions

---

### Scraping show info

.small[
```{r}
scrape_show_info <- function(x){

  title <- x %>%
    html_node("h1") %>%
    html_text(trim = TRUE) 

  runtime <- x %>%
    html_node("time") %>%
    html_text() %>% # could use trim = TRUE instead of str_ functions
    str_replace("\\n", "") %>%
    str_trim()
  
  genres <- x %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_c(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

.small[
```{r}
scrape_show_info(pb)
scrape_show_info(st)
scrape_show_info(fr)
```
]

---

.question[
How would you update the following function to use the URL of the page as an argument?
]

.small[
```{r eval=FALSE}
scrape_show_info <- function(x){

  title <- x %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- x %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()
  
  genres <- x %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

.small[
```{r}
scrape_show_info <- function(x){
  
{{  y <- read_html(x) }}

  title <- y %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- y %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()

  genres <- y %>%
    html_nodes(".txt-block~ .canwrap a") %>%
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

### Let's check

.small[
```{r}
pb_url <- "https://www.imdb.com/title/tt2442560/"
st_url <- "https://www.imdb.com/title/tt4574334/"
fr_url <- "https://www.imdb.com/title/tt0108778/"
```
]
--
.small[
```{r}
scrape_show_info(pb_url)
scrape_show_info(st_url)
scrape_show_info(fr_url)
```
]

---

class: center, middle

# Automation

---

.question[
You now have a function that will scrape the relevant info on shows given its URL. Where can we get a list of URLs of top 100 most popular TV shows on IMDB? Write the code for doing this in your teams.
]

---

```{r}
urls <- read_html("http://www.imdb.com/chart/tvmeter") %>%
  html_nodes(".titleColumn a") %>%
  html_attr("href") %>%
  paste("http://www.imdb.com", ., sep = "")
```

```{r echo=FALSE}
urls
```

---

### Go to each page, scrape show info 

Now we need a way to programatically direct R to each page on the `urls` list and run the `scrape_show_info` function on that page.

.small[
```{r}
scrape_show_info(urls[1])
scrape_show_info(urls[2])
scrape_show_info(urls[3])
```
]

---

class: middle

### Oh no! 

### 1. We're not scraping genre for every TV show!
### 2. We're repeating our code again!

---

### Update genre code

.small[
```{r}
scrape_show_info <- function(x){
  
  y <- read_html(x) 

  title <- y %>%
    html_node("h1") %>%
    html_text() %>%
    str_trim()

  runtime <- y %>%
    html_node("time") %>%
    html_text() %>%
    str_replace("\\n", "") %>%
    str_trim()

  genres <- y %>%
    html_nodes(".see-more.canwrap~ .canwrap a") %>% #<<
    html_text() %>%
    str_trim() %>%
    paste(collapse = ", ")
  
  tibble(title = title, runtime = runtime, genres = genres)
}
```
]

---

### Try again: go to each page, scrape show info 

```{r}
scrape_show_info(urls[1])
scrape_show_info(urls[2])
scrape_show_info(urls[3])
```

--

**... but we're still repeating our code!**
---

### Automation 

- We need a way to programatically repeat the code

- There are two ways to do this: 
    - use a **`for`** loop
    - **`map`**ping with functional programming
    
---

### `for` loops

- **`for`** loops are the simplest and most common type of loop in R
- Iterate through the elements of a vector and evaluate the code block for each

**Goal**: Scrape info from individual pages of TV shows using iteration with for loops. We'll use only 5 shows for now to keep things simple.

---

### `for` loop

### 1) Set up a tibble to store the results

```{r}
n <- 5
top_n_shows <- tibble( title = rep(NA, n), 
                       runtime = rep(NA, n), 
                       genres = rep(NA, n), 
                       epsiodes = rep(NA, n), 
                       keywords = rep(NA, n)
  )
top_n_shows
```

---

### `for` loop

### 2) Iterate through urls to scrape data and save results

```{r}
for(i in 1:n){
  top_n_shows[i, ] = scrape_show_info(urls[i])
}
top_n_shows
```

---

### `map`ping

- **`map`** functions transform the input by applying a function to each element and returning an object the same length as the input

- There are various map functions (e.g. `map_lgl()`, `map_chr()`, `map_dbl()`, `map_df()`)
    - each of which return a different type of object (logical, character, double, and data frame, respectively)

--

- We will `map` the `scrape_show_info` function to each element of `urls`   
    - This will go to each url at a time and get the info
    
**Goal:** Scrape info from individual pages of TV shows using functional programming with mapping. We'll use only 5 shows for now to keep things simple.

---

### `map`: Go to each page, scrape show info 

```{r}
top_n_shows <- map_df(urls[1:n], scrape_show_info)
top_n_shows
```

---

### Slow down the function

- If you get `HTTP Error 429 (Too man requests)` you might want to slow down your hits.

- You can add a `Sys.sleep()` call to slow down your function:

```{r eval=FALSE}
scrape_show_info <- function(x){
#suspend execution between 0 to 1 seconds

  {{  Sys.sleep(runif(1)) }}
  
  ...

}
```
