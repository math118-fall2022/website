---
title: "Webscrape"
subtitle: "Part 2"
author: "Dr. Maria Tackett"
date: "09.26.19"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta199-slides.css"
    logo: img/sta199-sticker-icon.png
    lib_dir: libs
    nature: 
      highlightLines: true
      highlightStyle: github
      countIncrementalSlides: false
      slideNumberFormat: "%current%"
---

layout: true

<div class="my-footer">
<span>
<a href="http://datasciencebox.org" target="_blank">datasciencebox.org</a>
</span>
</div> 

---

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(DT)
library(emo)
library(openintro)
library(infer)
library(gridExtra)
```

```{r setup, include=FALSE}
# R options
options(
  htmltools.dir.version = FALSE, # for blogdown
  show.signif.stars = FALSE,     # for regression output
  warm = 1
  )
# Set dpi and height for images
knitr::opts_chunk$set(fig.height = 2.5, fig.width = 5, dpi = 300) 
# ggplot2 color palette with gray
color_palette <- list(gray = "#999999", 
                      salmon = "#E69F00", 
                      lightblue = "#56B4E9", 
                      green = "#009E73", 
                      yellow = "#F0E442", 
                      darkblue = "#0072B2", 
                      red = "#D55E00", 
                      purple = "#CC79A7")
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
# For magick
dev.off <- function(){
  invisible(grDevices::dev.off())
}
# For ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

class: middle, center

### [Click for PDF of slides](06a-webscrape-part2.pdf)

---

### Announcements

- Writing Exercise #2 initial draft - **due TODAY at 11:59p**
    - Peer Review available tomorrow and due Sunday 9/29 at 11:59p

- HW 02 - **due TODAY at 11:59p**

- Team Feedback #1 **due TODAY at 11:59p**
    - Please provide honest and constructive feedback. This team feedback will be graded for completion.
    

---

### Check in: Regrade Requests

- All regrade requests should be submitted through Gradescope. [See updated course policy](https://www2.stat.duke.edu/courses/Fall19/sta199.001/policies.html)

- Only submit a regrade request if you still have concerns about your grade after you have attended office hours and asked a member of the teaching team to explain the feedback you received. This will ultimately help with your understanding of the course material and help the teaching team get an idea about points to clarify.

- **When you submit a regrade request, please indicate who you've talked with prior to submitting the request.**

- Professor Tackett is the only person who can update grades, so <u>do not</u> ask your TAs to regrade your assignment.
   
---

### Check in: Lab 04

- Will get Lab 04 assignment from RStudio Cloud project. 

- [Fill out form](https://forms.gle/Ci8XCcHh6ESvuac6A) with the name of the RStudio Cloud project for grading.

---

class: middle, center

# Web scraping 

```{r echo = F, message=FALSE}
library(rvest)

page <- read_html("http://www.imdb.com/chart/top")

titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()

years <- page %>%
  html_nodes(".secondaryInfo") %>%
  html_text() %>%
  str_replace("\\(", "") %>% # remove (
  str_replace("\\)", "") %>% # remove )
  as.numeric()

scores <- page %>%
  html_nodes(".imdbRating") %>%
  html_text() %>%
  as.numeric()
  
imdb_top_250 <- tibble(
  title = titles, 
  year = years, 
  score = scores
  )
```

---

### Clean up / enhance

May or may not be a lot of work depending on how messy the data are

- See if you like what you got:

```{r}
glimpse(imdb_top_250)
```

- Add a variable for rank
```{r}
imdb_top_250 <- imdb_top_250 %>%
  mutate(
    rank = 1:nrow(imdb_top_250)
  )
```

---

```{r echo=FALSE, results='asis'}
imdb_top_250 %>% head(10)%>% rbind(rep("...", 3)) %>% kable(format = "html")
```

---

### Analyze

.question[
How would you go about answering this question: Which 1995 movies made the list?
]

---

```{r}
imdb_top_250 %>% 
  filter(year == 1995)
```

---

### Analyze

.question[
How would you go about answering this question: Which years have the most movies on the list?
]

--

```{r}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(total = n()) %>%
  arrange(desc(total)) %>%
  head(5)
```

---

### Visualize

.question[
How would you go about creating this visualization: Visualize the average yearly score for movies that made it on the top 250 list over time.
]

--

.small[
```{r echo=FALSE}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(avg_score = mean(score)) %>%
  ggplot(aes(y = avg_score, x = year)) +
    geom_point() +
    geom_smooth(method = "lm") +
    xlab("year")
```
]

---

### Top Rated 

.question[
- Which year has the highest average score for movies that made the Top 250? 
]

--

.question[
- What is one reason we should write code to answer this question rather than look through the data?
- What is one reason we only want to print the year with the highest average rather than entire table?
]

---

### Potential challenges

- Unreliable formatting at the source
- Data broken into many pages
- ...

.question[
Compare the display of information at [raleigh.craigslist.org/search/apa](https://raleigh.craigslist.org/search/apa) to the list on the IMDB top 250 list. 

What challenges can you foresee in scraping a list of the available apartments?
]

---

class: middle, center

## Application Exercise

---

### Popular TV Shows

RStudio Cloud $\rightarrow$ Web scraping 

1. Scrape the list of most popular TV shows on IMDB: http://www.imdb.com/chart/tvmeter

2. Examine each of the first three (or however many you can get through) tv show subpage to also obtain genre and runtime.

3. Time permitting, also try to get the following:

    - How many episodes so far
    - Certificate
    - First five plot keywords
    - Country
    - Language

Add this information to the data frame you created in step 1.

<!-- Ended here on 9/26 -->

